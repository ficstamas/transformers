cnt_epochs: 30
batch_size: 64
tokenizer_name: "roberta-base"
model_name: "../transformers/configs/config_lsh_mlp-only.json"
path_corpus: "/mnt/storage/data/Corpora/tokenized/wiki-c4-amazon-pile-etc/roberta-base/512/tokenized.jsonl"
path_results: ./tmp/lsh_run/
initial_lr: 0.0001
max_lr: 0.001
cnt_samples_per_epoch: 100000000
gradient_clip_val: 10.0
weight_decay: 0.01
log_every_n_steps: 100
max_length: 512
path_results: "/storage/data/Model_snapshots"
accumulate_batches:
  0: 1
  4: 2
  8: 3
  16: 4
  32: 5
callbacks:
  monitor:
    module: langmo.callbacks.monitor
    class_name: Monitor
  hashing:
    working_directory: "../transformers/src/"
    module: transformers.models.lsh.callbacks
    class_name: AttachCallback
ddp_strategy_params:
  find_unused_parameters: true
